# ğŸ“„ RAG PDF Chatbot

A conversational AI app that lets you **upload any PDF and chat with it**. Ask questions, get context-aware answers, and have multi-turn conversations â€” all powered by Retrieval-Augmented Generation (RAG).

ğŸš€ **Live Demo** â†’ [ask-me-from-pdf.streamlit.app](https://ask-me-from-pdf.streamlit.app)

---

## âœ¨ Features

- ğŸ“‚ Upload any PDF document
- ğŸ’¬ Ask questions in natural language
- ğŸ§  Multi-turn conversation with memory
- âš¡ Fast responses powered by Groq LLM
- ğŸ” Semantic search using sentence embeddings
- ğŸ—„ï¸ Vector storage with ChromaDB

---

## ğŸ› ï¸ Tech Stack

| Layer | Technology |
|---|---|
| Frontend / UI | Streamlit |
| LLM | Groq (LLaMA 3) |
| Embeddings | Sentence Transformers |
| Vector Store | ChromaDB |
| PDF Parsing | PyPDF |
| Language | Python 3.11 |

---

## ğŸ“ Project Structure

```
rag-project/
â”œâ”€â”€ app.py              # Streamlit UI and chat logic
â”œâ”€â”€ ingest.py           # PDF loading, chunking, embedding
â”œâ”€â”€ query.py            # Retrieval and answer generation
â”œâ”€â”€ requirements.txt    # Project dependencies
â”œâ”€â”€ .env                # API keys (not pushed to GitHub)
â””â”€â”€ README.md
```

---

## âš™ï¸ How It Works

```
PDF Upload
    â†“
Split into chunks (ingest.py)
    â†“
Convert chunks to embeddings (Sentence Transformers)
    â†“
Store embeddings in ChromaDB
    â†“
User asks a question
    â†“
Find most relevant chunks (semantic search)
    â†“
Send chunks + question + chat history to Groq LLM
    â†“
Return answer to user
```

---

## ğŸš€ Run Locally

**1. Clone the repository**
```bash
git clone https://github.com/yourusername/AI-Projects.git
cd AI-Projects/rag-project
```

**2. Create and activate virtual environment**
```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Mac/Linux
source venv/bin/activate
```

**3. Install dependencies**
```bash
pip install -r requirements.txt
```

**4. Set up environment variables**

Create a `.env` file in the project root:
```
GROQ_API_KEY=your_groq_api_key_here
```

Get your free Groq API key at [console.groq.com](https://console.groq.com)

**5. Run the app**
```bash
streamlit run app.py
```

Open `http://localhost:8501` in your browser.

---

## â˜ï¸ Deployment

This app is deployed on **Streamlit Community Cloud**.

To deploy your own instance:
1. Fork this repository
2. Go to [share.streamlit.io](https://share.streamlit.io)
3. Connect your GitHub repo
4. Add `GROQ_API_KEY` in the Secrets section
5. Deploy

---

## ğŸ“Œ Environment Variables

| Variable | Description |
|---|---|
| `GROQ_API_KEY` | Your Groq API key from console.groq.com |

---

## ğŸ“„ License

MIT License â€” feel free to use and modify.